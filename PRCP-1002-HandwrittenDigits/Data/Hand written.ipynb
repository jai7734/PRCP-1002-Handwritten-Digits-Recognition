{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8402a229-b1ea-42cf-8adf-e30bf47a28c1",
   "metadata": {},
   "source": [
    "### Domain Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3673d3b-fe2c-4d7a-a1f1-1e1cab24e653",
   "metadata": {},
   "source": [
    "The MNIST (Modified National Institute of Standards and Technology) dataset is a widely used benchmark in the domain of computer vision and machine learning, particularly for image classification tasks. It consists of 70,000 grayscale images of handwritten digits, divided into 60,000 training images and 10,000 test images, each with dimensions of 28x28 pixels. The dataset represents digits (0 through 9), with corresponding labels for supervised learning tasks. MNIST is commonly used to evaluate and compare classification algorithms, including traditional machine learning models like SVM and KNN, as well as modern deep learning architectures such as Convolutional Neural Networks (CNNs). Its simplicity, standardized format, and relevance to real-world tasks make it an ideal starting point for developing and benchmarking image recognition models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c14e6e-016b-4492-906e-a944419db1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff27a73a-30a9-4824-af08-10ba621ebe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d3100f-aed0-4fd8-bc27-34e36feb2a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display 4 sample images from the training set\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(x_train[i], cmap='gray')  # Display the image in grayscale\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')  # Turn off the axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016d1eaf-d584-4b00-9aa0-7f1a1c8a635d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c9b3c31390>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZzElEQVR4nO3df2hV9/3H8detxlvrkjuiJvdmxpB1yjZ1gj+mhlZjqXcGav3RQmzHiP9IO3+AROeWumFWNlOESv/I6ljZnK51DUPrHEpthiY6bIqKorhW0hqbDBOCmbs3iRqnfr5/iPe728Qf53qv79zk+YAD5t7z8b49Pfjs8d6c+JxzTgAAGHjMegAAwOBFhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgJmh1gN81a1bt3Tx4kVlZmbK5/NZjwMA8Mg5p87OTuXl5emxx+59rdPvInTx4kXl5+dbjwEAeEgtLS0aM2bMPffpd/8cl5mZaT0CACAJHuTv85RF6O2331ZhYaEef/xxTZ06VUeOHHmgdfwTHAAMDA/y93lKIlRTU6M1a9Zow4YNOnnypJ5++mmVlJSoubk5FS8HAEhTvlTcRXvGjBmaMmWKtm7dGnvsO9/5jhYtWqSqqqp7ro1GowoEAskeCQDwiEUiEWVlZd1zn6RfCV2/fl0nTpxQOByOezwcDuvo0aO99u/p6VE0Go3bAACDQ9IjdOnSJd28eVO5ublxj+fm5qqtra3X/lVVVQoEArGNT8YBwOCRsg8mfPUNKedcn29SVVRUKBKJxLaWlpZUjQQA6GeS/n1Co0aN0pAhQ3pd9bS3t/e6OpIkv98vv9+f7DEAAGkg6VdCw4YN09SpU1VbWxv3eG1trYqKipL9cgCANJaSOyaUl5frRz/6kaZNm6ZZs2bpd7/7nZqbm/Xqq6+m4uUAAGkqJREqLS1VR0eHXn/9dbW2tmrixInav3+/CgoKUvFyAIA0lZLvE3oYfJ8QAAwMJt8nBADAgyJCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzQ60HAO5n3bp1ntcMHz48odf63ve+53nNiy++mNBrebV161bPaz7++OOEXutPf/pTQusAr7gSAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDM+JxzznqI/xWNRhUIBKzHQIrU1NR4XvOobhA6EH3xxRcJrXv22Wc9r2lubk7otTBwRSIRZWVl3XMfroQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNDrQdA+hqINyP97LPPPK85cOCA5zXf/OY3Pa9ZsGCB5zVPPvmk5zWS9MMf/tDzmqqqqoReC4MbV0IAADNECABgJukRqqyslM/ni9uCwWCyXwYAMACk5D2hCRMm6O9//3vs6yFDhqTiZQAAaS4lERo6dChXPwCA+0rJe0KNjY3Ky8tTYWGhli5dqvPnz991356eHkWj0bgNADA4JD1CM2bM0I4dO3TgwAG98847amtrU1FRkTo6Ovrcv6qqSoFAILbl5+cneyQAQD+V9AiVlJTohRde0KRJk/Tss89q3759kqTt27f3uX9FRYUikUhsa2lpSfZIAIB+KuXfrDpixAhNmjRJjY2NfT7v9/vl9/tTPQYAoB9K+fcJ9fT06NNPP1UoFEr1SwEA0kzSI7Ru3TrV19erqalJn3zyiV588UVFo1GVlZUl+6UAAGku6f8c969//UsvvfSSLl26pNGjR2vmzJlqaGhQQUFBsl8KAJDmkh6h999/P9m/JVJs2rRpCa1bvHhxkifp29mzZz2vef755xN6rUuXLnle09XV5XnNsGHDPK9paGjwvGby5Mme10jSyJEjE1oHeMW94wAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAMyn/oXbo/xL9WU8+n8/zmkRuRvqDH/zA85rW1lbPax6ltWvXel7z3e9+NwWT9O3OT0QGUo0rIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJjhLtrQ3/72t4TWfetb3/K8prOz0/Oaf//7357X9HdLly71vCYjIyMFkwC2uBICAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMxwA1Mk7Msvv7QeoV/4yU9+4nnN+PHjUzBJb5988skjXQd4xZUQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGG5gC/+O5557zvOb111/3vGbYsGGe17S3t3teU1FR4XmNJF25ciWhdYBXXAkBAMwQIQCAGc8ROnz4sBYsWKC8vDz5fD7t2bMn7nnnnCorK5WXl6fhw4eruLhYZ8+eTda8AIABxHOEuru7NXnyZFVXV/f5/ObNm7VlyxZVV1fr2LFjCgaDmjdvnjo7Ox96WADAwOL5gwklJSUqKSnp8znnnN566y1t2LBBS5YskSRt375dubm52rlzp1555ZWHmxYAMKAk9T2hpqYmtbW1KRwOxx7z+/2aM2eOjh492ueanp4eRaPRuA0AMDgkNUJtbW2SpNzc3LjHc3NzY899VVVVlQKBQGzLz89P5kgAgH4sJZ+O8/l8cV8753o9dkdFRYUikUhsa2lpScVIAIB+KKnfrBoMBiXdviIKhUKxx9vb23tdHd3h9/vl9/uTOQYAIE0k9UqosLBQwWBQtbW1sceuX7+u+vp6FRUVJfOlAAADgOcroa6uLn3++eexr5uamnTq1CllZ2dr7NixWrNmjTZt2qRx48Zp3Lhx2rRpk5544gm9/PLLSR0cAJD+PEfo+PHjmjt3buzr8vJySVJZWZn++Mc/av369bp69apWrFihy5cva8aMGfroo4+UmZmZvKkBAAOC5wgVFxfLOXfX530+nyorK1VZWfkwcwEmpk2b5nlNIjcjTURNTY3nNfX19SmYBEge7h0HADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0n9yapAf7Fnz56E1oXD4eQOchc7duzwvObnP/95CiYBbHElBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4Qam6PdCoZDnNUVFRQm9lt/v97zm0qVLntf86le/8rymq6vL8xqgv+NKCABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwww1M0e/t2rXL85qRI0emYJK+vfvuu57XfPHFFymYBEg/XAkBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGa4gSkeqeeff97zmilTpqRgkr7V1dV5XrNx48bkDwIMElwJAQDMECEAgBnPETp8+LAWLFigvLw8+Xw+7dmzJ+75ZcuWyefzxW0zZ85M1rwAgAHEc4S6u7s1efJkVVdX33Wf+fPnq7W1Nbbt37//oYYEAAxMnj+YUFJSopKSknvu4/f7FQwGEx4KADA4pOQ9obq6OuXk5Gj8+PFavny52tvb77pvT0+PotFo3AYAGBySHqGSkhK99957OnjwoN58800dO3ZMzzzzjHp6evrcv6qqSoFAILbl5+cneyQAQD+V9O8TKi0tjf164sSJmjZtmgoKCrRv3z4tWbKk1/4VFRUqLy+PfR2NRgkRAAwSKf9m1VAopIKCAjU2Nvb5vN/vl9/vT/UYAIB+KOXfJ9TR0aGWlhaFQqFUvxQAIM14vhLq6urS559/Hvu6qalJp06dUnZ2trKzs1VZWakXXnhBoVBIFy5c0GuvvaZRo0Zp8eLFSR0cAJD+PEfo+PHjmjt3buzrO+/nlJWVaevWrTpz5ox27Nih//znPwqFQpo7d65qamqUmZmZvKkBAAOC5wgVFxfLOXfX5w8cOPBQAyF9jBw50vOa1157zfOajIwMz2sSderUKc9rurq6kj8IMEhw7zgAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYSflPVsXAtXbtWs9rpk+fnoJJetuzZ09C6zZu3JjcQQDcE1dCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZn3POWQ/xv6LRqAKBgPUYeADXrl3zvCYjIyMFk/Q2ZsyYhNa1trYmeRJg8IpEIsrKyrrnPlwJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmhloPAKRCdnZ2Quv++9//JnkSW5FIJKF1iRyHRG5O+6huVvz1r389oXXl5eXJHSSJbt68mdC6n/70p57XXLlyJaHXehBcCQEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZriBKQak06dPW4/QL/zlL39JaF1ra6vnNbm5uZ7XlJaWel6Dh9PW1uZ5za9//esUTHIbV0IAADNECABgxlOEqqqqNH36dGVmZionJ0eLFi3SuXPn4vZxzqmyslJ5eXkaPny4iouLdfbs2aQODQAYGDxFqL6+XitXrlRDQ4Nqa2t148YNhcNhdXd3x/bZvHmztmzZourqah07dkzBYFDz5s1TZ2dn0ocHAKQ3Tx9M+PDDD+O+3rZtm3JycnTixAnNnj1bzjm99dZb2rBhg5YsWSJJ2r59u3Jzc7Vz50698soryZscAJD2Huo9oTs/OvjOj1JuampSW1ubwuFwbB+/3685c+bo6NGjff4ePT09ikajcRsAYHBIOELOOZWXl+upp57SxIkTJf3/R/+++lHN3Nzcu34ssKqqSoFAILbl5+cnOhIAIM0kHKFVq1bp9OnT+vOf/9zrOZ/PF/e1c67XY3dUVFQoEonEtpaWlkRHAgCkmYS+WXX16tXau3evDh8+rDFjxsQeDwaDkm5fEYVCodjj7e3td/1GNr/fL7/fn8gYAIA05+lKyDmnVatWaffu3Tp48KAKCwvjni8sLFQwGFRtbW3ssevXr6u+vl5FRUXJmRgAMGB4uhJauXKldu7cqb/+9a/KzMyMvc8TCAQ0fPhw+Xw+rVmzRps2bdK4ceM0btw4bdq0SU888YRefvnllPwBAADpy1OEtm7dKkkqLi6Oe3zbtm1atmyZJGn9+vW6evWqVqxYocuXL2vGjBn66KOPlJmZmZSBAQADh88556yH+F/RaFSBQMB6DDyA3bt3e16zcOHCFEyCweTGjRue19y6dSsFk/Rt7969ntccP348BZP07ciRI57XNDQ0JPRakUhEWVlZ99yHe8cBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADHfRxiO1fv16z2syMjJSMEnyTJgwwfOa0tLSFEySPH/4wx88r7lw4ULyB+nDrl27PK/57LPPUjAJ7oe7aAMA+jUiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAw3MAUApAQ3MAUA9GtECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGU8Rqqqq0vTp05WZmamcnBwtWrRI586di9tn2bJl8vl8cdvMmTOTOjQAYGDwFKH6+nqtXLlSDQ0Nqq2t1Y0bNxQOh9Xd3R233/z589Xa2hrb9u/fn9ShAQADw1AvO3/44YdxX2/btk05OTk6ceKEZs+eHXvc7/crGAwmZ0IAwID1UO8JRSIRSVJ2dnbc43V1dcrJydH48eO1fPlytbe33/X36OnpUTQajdsAAIODzznnElnonNPChQt1+fJlHTlyJPZ4TU2Nvva1r6mgoEBNTU36xS9+oRs3bujEiRPy+/29fp/Kykr98pe/TPxPAADolyKRiLKysu69k0vQihUrXEFBgWtpabnnfhcvXnQZGRlu165dfT5/7do1F4lEYltLS4uTxMbGxsaW5lskErlvSzy9J3TH6tWrtXfvXh0+fFhjxoy5576hUEgFBQVqbGzs83m/39/nFRIAYODzFCHnnFavXq0PPvhAdXV1KiwsvO+ajo4OtbS0KBQKJTwkAGBg8vTBhJUrV+rdd9/Vzp07lZmZqba2NrW1tenq1auSpK6uLq1bt04ff/yxLly4oLq6Oi1YsECjRo3S4sWLU/IHAACkMS/vA+ku/+63bds255xzV65cceFw2I0ePdplZGS4sWPHurKyMtfc3PzArxGJRMz/HZONjY2N7eG3B3lPKOFPx6VKNBpVIBCwHgMA8JAe5NNx3DsOAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCm30XIOWc9AgAgCR7k7/N+F6HOzk7rEQAASfAgf5/7XD+79Lh165YuXryozMxM+Xy+uOei0ajy8/PV0tKirKwsowntcRxu4zjcxnG4jeNwW384Ds45dXZ2Ki8vT489du9rnaGPaKYH9thjj2nMmDH33CcrK2tQn2R3cBxu4zjcxnG4jeNwm/VxCAQCD7Rfv/vnOADA4EGEAABm0ipCfr9fGzdulN/vtx7FFMfhNo7DbRyH2zgOt6Xbceh3H0wAAAweaXUlBAAYWIgQAMAMEQIAmCFCAAAzaRWht99+W4WFhXr88cc1depUHTlyxHqkR6qyslI+ny9uCwaD1mOl3OHDh7VgwQLl5eXJ5/Npz549cc8751RZWam8vDwNHz5cxcXFOnv2rM2wKXS/47Bs2bJe58fMmTNthk2RqqoqTZ8+XZmZmcrJydGiRYt07ty5uH0Gw/nwIMchXc6HtIlQTU2N1qxZow0bNujkyZN6+umnVVJSoubmZuvRHqkJEyaotbU1tp05c8Z6pJTr7u7W5MmTVV1d3efzmzdv1pYtW1RdXa1jx44pGAxq3rx5A+4+hPc7DpI0f/78uPNj//79j3DC1Kuvr9fKlSvV0NCg2tpa3bhxQ+FwWN3d3bF9BsP58CDHQUqT88Glie9///vu1VdfjXvs29/+tvvZz35mNNGjt3HjRjd58mTrMUxJch988EHs61u3brlgMOjeeOON2GPXrl1zgUDA/fa3vzWY8NH46nFwzrmysjK3cOFCk3mstLe3O0muvr7eOTd4z4evHgfn0ud8SIsroevXr+vEiRMKh8Nxj4fDYR09etRoKhuNjY3Ky8tTYWGhli5dqvPnz1uPZKqpqUltbW1x54bf79ecOXMG3bkhSXV1dcrJydH48eO1fPlytbe3W4+UUpFIRJKUnZ0tafCeD189Dnekw/mQFhG6dOmSbt68qdzc3LjHc3Nz1dbWZjTVozdjxgzt2LFDBw4c0DvvvKO2tjYVFRWpo6PDejQzd/77D/ZzQ5JKSkr03nvv6eDBg3rzzTd17NgxPfPMM+rp6bEeLSWccyovL9dTTz2liRMnShqc50Nfx0FKn/Oh391F+16++qMdnHO9HhvISkpKYr+eNGmSZs2apSeffFLbt29XeXm54WT2Bvu5IUmlpaWxX0+cOFHTpk1TQUGB9u3bpyVLlhhOlhqrVq3S6dOn9Y9//KPXc4PpfLjbcUiX8yEtroRGjRqlIUOG9Po/mfb29l7/xzOYjBgxQpMmTVJjY6P1KGbufDqQc6O3UCikgoKCAXl+rF69Wnv37tWhQ4fifvTLYDsf7nYc+tJfz4e0iNCwYcM0depU1dbWxj1eW1uroqIio6ns9fT06NNPP1UoFLIexUxhYaGCwWDcuXH9+nXV19cP6nNDkjo6OtTS0jKgzg/nnFatWqXdu3fr4MGDKiwsjHt+sJwP9zsOfem354PhhyI8ef/9911GRob7/e9/7/75z3+6NWvWuBEjRrgLFy5Yj/bIrF271tXV1bnz58+7hoYG99xzz7nMzMwBfww6OzvdyZMn3cmTJ50kt2XLFnfy5En35ZdfOuece+ONN1wgEHC7d+92Z86ccS+99JILhUIuGo0aT55c9zoOnZ2dbu3ate7o0aOuqanJHTp0yM2aNct94xvfGFDH4cc//rELBAKurq7Otba2xrYrV67E9hkM58P9jkM6nQ9pEyHnnPvNb37jCgoK3LBhw9yUKVPiPo44GJSWlrpQKOQyMjJcXl6eW7JkiTt79qz1WCl36NAhJ6nXVlZW5py7/bHcjRs3umAw6Px+v5s9e7Y7c+aM7dApcK/jcOXKFRcOh93o0aNdRkaGGzt2rCsrK3PNzc3WYydVX39+SW7btm2xfQbD+XC/45BO5wM/ygEAYCYt3hMCAAxMRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZ/wNSm9TRKEG5vwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb1bc6e-35f8-4dad-b13d-6bd9758509e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec9f87f7-5769-491f-949c-3df498390b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f26f2-9729-4189-b13c-d0d5344759f5",
   "metadata": {},
   "source": [
    "### Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a1d845-2bda-4d1e-9af1-fae0bc6cc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b63c555-f53f-4d9b-ba9e-d02f8569b6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0940b9-ddc3-42e8-bdfd-bbe7492a4bdd",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d20881-66fb-4c60-8e75-276518cbf92b",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4502ba8-d675-4a93-81fe-ac70aec52527",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b299238e-c487-45b6-9768-acc1fd5ccfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G phanindra\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1dd7537-0bb5-4bc1-a603-3e3359cafec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3a83a9d-4d45-4fb7-ab39-6b3a2fb2f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fa63359-0a82-4307-9344-065658167f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.8671e-05 - val_accuracy: 0.9788 - val_loss: 0.1317\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9718 - val_loss: 0.1686\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9772 - val_loss: 0.1397\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.2445e-04 - val_accuracy: 0.9779 - val_loss: 0.1395\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.3833e-04 - val_accuracy: 0.9784 - val_loss: 0.1373\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.1195e-05 - val_accuracy: 0.9784 - val_loss: 0.1373\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.6781e-05 - val_accuracy: 0.9783 - val_loss: 0.1379\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.6405e-05 - val_accuracy: 0.9787 - val_loss: 0.1390\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.8699e-05 - val_accuracy: 0.9786 - val_loss: 0.1393\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.8660e-05 - val_accuracy: 0.9782 - val_loss: 0.1403\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.3708e-05 - val_accuracy: 0.9750 - val_loss: 0.1616\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0223 - val_accuracy: 0.9768 - val_loss: 0.1497\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.1787e-04 - val_accuracy: 0.9772 - val_loss: 0.1518\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 9.6754e-04 - val_accuracy: 0.9777 - val_loss: 0.1472\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 9.2068e-04 - val_accuracy: 0.9753 - val_loss: 0.1707\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9778 - val_loss: 0.1524\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.0017e-04 - val_accuracy: 0.9774 - val_loss: 0.1543\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 1.6797e-04 - val_accuracy: 0.9793 - val_loss: 0.1443\n",
      "Epoch 19/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.7770e-05 - val_accuracy: 0.9794 - val_loss: 0.1441\n",
      "Epoch 20/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.2386e-05 - val_accuracy: 0.9795 - val_loss: 0.1442\n",
      "Epoch 21/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.3228e-05 - val_accuracy: 0.9793 - val_loss: 0.1451\n",
      "Epoch 22/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.7786e-05 - val_accuracy: 0.9796 - val_loss: 0.1450\n",
      "Epoch 23/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.1313e-05 - val_accuracy: 0.9800 - val_loss: 0.1451\n",
      "Epoch 24/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8498e-05 - val_accuracy: 0.9795 - val_loss: 0.1468\n",
      "Epoch 25/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.6515e-05 - val_accuracy: 0.9796 - val_loss: 0.1470\n",
      "Epoch 26/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3683e-05 - val_accuracy: 0.9800 - val_loss: 0.1485\n",
      "Epoch 27/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0082 - val_accuracy: 0.9751 - val_loss: 0.1648\n",
      "Epoch 28/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9764 - val_loss: 0.1638\n",
      "Epoch 29/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9768 - val_loss: 0.1677\n",
      "Epoch 30/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 4.8302e-04 - val_accuracy: 0.9780 - val_loss: 0.1617\n",
      "Epoch 31/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 7.8090e-05 - val_accuracy: 0.9783 - val_loss: 0.1575\n",
      "Epoch 32/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.8362e-05 - val_accuracy: 0.9787 - val_loss: 0.1570\n",
      "Epoch 33/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.1797e-05 - val_accuracy: 0.9786 - val_loss: 0.1575\n",
      "Epoch 34/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8891e-05 - val_accuracy: 0.9789 - val_loss: 0.1569\n",
      "Epoch 35/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.5089e-05 - val_accuracy: 0.9789 - val_loss: 0.1575\n",
      "Epoch 36/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3161e-05 - val_accuracy: 0.9793 - val_loss: 0.1581\n",
      "Epoch 37/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.0409e-05 - val_accuracy: 0.9793 - val_loss: 0.1590\n",
      "Epoch 38/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2610e-05 - val_accuracy: 0.9795 - val_loss: 0.1600\n",
      "Epoch 39/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.4828e-06 - val_accuracy: 0.9793 - val_loss: 0.1603\n",
      "Epoch 40/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.0078e-05 - val_accuracy: 0.9676 - val_loss: 0.2489\n",
      "Epoch 41/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0110 - val_accuracy: 0.9770 - val_loss: 0.1768\n",
      "Epoch 42/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0010 - val_accuracy: 0.9779 - val_loss: 0.1717\n",
      "Epoch 43/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 4.6466e-04 - val_accuracy: 0.9783 - val_loss: 0.1755\n",
      "Epoch 44/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 5.5790e-04 - val_accuracy: 0.9787 - val_loss: 0.1688\n",
      "Epoch 45/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.7980e-05 - val_accuracy: 0.9786 - val_loss: 0.1679\n",
      "Epoch 46/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8290e-05 - val_accuracy: 0.9787 - val_loss: 0.1679\n",
      "Epoch 47/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4931e-05 - val_accuracy: 0.9787 - val_loss: 0.1675\n",
      "Epoch 48/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1609e-05 - val_accuracy: 0.9793 - val_loss: 0.1679\n",
      "Epoch 49/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1038e-05 - val_accuracy: 0.9794 - val_loss: 0.1674\n",
      "Epoch 50/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.5869e-06 - val_accuracy: 0.9797 - val_loss: 0.1674\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,batch_size=64,epochs=50,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f627ea5c-d362-4291-b32e-c63fe5652a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9769 - loss: 0.1948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15807943046092987, 0.9797999858856201]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f57a8b-7be3-4837-8a75-7e4bf5c6b012",
   "metadata": {},
   "source": [
    "### CNN Optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b76c8fe7-412f-42aa-a386-e0b1d8687e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,370</span> (435.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,370\u001b[0m (435.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,922</span> (433.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,922\u001b[0m (433.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 68ms/step - accuracy: 0.8579 - loss: 0.4548 - val_accuracy: 0.9770 - val_loss: 0.0778\n",
      "Epoch 2/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 68ms/step - accuracy: 0.9757 - loss: 0.0816 - val_accuracy: 0.9807 - val_loss: 0.0594\n",
      "Epoch 3/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 67ms/step - accuracy: 0.9838 - loss: 0.0573 - val_accuracy: 0.9860 - val_loss: 0.0470\n",
      "Epoch 4/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 68ms/step - accuracy: 0.9867 - loss: 0.0439 - val_accuracy: 0.9833 - val_loss: 0.0561\n",
      "Epoch 5/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 68ms/step - accuracy: 0.9903 - loss: 0.0362 - val_accuracy: 0.9863 - val_loss: 0.0517\n",
      "Epoch 6/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 68ms/step - accuracy: 0.9901 - loss: 0.0335 - val_accuracy: 0.9868 - val_loss: 0.0476\n",
      "Epoch 7/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 68ms/step - accuracy: 0.9923 - loss: 0.0251 - val_accuracy: 0.9862 - val_loss: 0.0517\n",
      "Epoch 8/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 68ms/step - accuracy: 0.9921 - loss: 0.0247 - val_accuracy: 0.9827 - val_loss: 0.0695\n",
      "Epoch 9/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 68ms/step - accuracy: 0.9925 - loss: 0.0230 - val_accuracy: 0.9880 - val_loss: 0.0466\n",
      "Epoch 10/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 68ms/step - accuracy: 0.9939 - loss: 0.0187 - val_accuracy: 0.9887 - val_loss: 0.0457\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9862 - loss: 0.0571\n",
      "Test Accuracy: 0.9890000224113464\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Reshape the data to fit the model (adding a single channel as it's grayscale)\n",
    "x_train1 = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test1 = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "y_train1 = to_categorical(y_train, 10)\n",
    "y_test1 = to_categorical(y_test, 10)\n",
    "\n",
    "# Create the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())  # Batch Normalization\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())  # Batch Normalization\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Third convolutional layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())  # Batch Normalization\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected dense layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
    "\n",
    "# Output layer with 10 classes (for digits 0-9)\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train1, y_train1, epochs=10, batch_size=64, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(x_test1, y_test1)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5ddf76-5b1c-4f60-99b9-6796370fae62",
   "metadata": {},
   "source": [
    "### Preprocessing for classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aef218e7-47f2-43ca-a176-25d766f1a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images into 1D arrays\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train_resampled, x_val_resampled, y_train_resampled, y_val_resampled = train_test_split(x_train_flat, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c1997a-9e5f-4dc2-ab19-52e8bddd4dd9",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b41395-5f2c-4f0c-bed5-c15994e29c38",
   "metadata": {},
   "source": [
    "### SVM with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d16d080d-c25b-4ae5-88d8-143caea6c801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Validation Accuracy: 0.9775833333333334\n",
      "SVM Test Accuracy: 0.9777\n"
     ]
    }
   ],
   "source": [
    "# Create and train the SVM model\n",
    "svm_model = svm.SVC(kernel='rbf')\n",
    "svm_model.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# Validate on the validation set\n",
    "y_pred_val_svm = svm_model.predict(x_val_resampled)\n",
    "print(f'SVM Validation Accuracy: {accuracy_score(y_val_resampled, y_pred_val_svm)}')\n",
    "\n",
    "# Test on the test set\n",
    "y_pred_test_svm = svm_model.predict(x_test_flat)\n",
    "print(f'SVM Test Accuracy: {accuracy_score(y_test, y_pred_test_svm)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeaa37d8-b231-445c-bb1d-716f8687071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Training Accuracy: 0.9895833333333334\n"
     ]
    }
   ],
   "source": [
    "# Calculate Training Accuracy\n",
    "y_pred_train_svm = svm_model.predict(x_train_resampled)\n",
    "training_accuracy = accuracy_score(y_train_resampled, y_pred_train_svm)\n",
    "print(f'SVM Training Accuracy: {training_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa24583-27e1-4adc-9831-06896471f47e",
   "metadata": {},
   "source": [
    "### SVM without validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a07046cc-52e0-4eb7-b0a8-5d0fc3b1ffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "svm_model1 = svm.SVC(kernel='rbf')\n",
    "svm_model1.fit(x_train_flat, y_train)\n",
    "\n",
    "# Test on the test set\n",
    "y_pred_test_svm1 = svm_model1.predict(x_test_flat)\n",
    "print(f'SVM Test Accuracy: {accuracy_score(y_test, y_pred_test_svm1)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce170989-de4a-44ca-80f4-27006116a066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Training Accuracy: 0.9899166666666667\n"
     ]
    }
   ],
   "source": [
    "# Calculate Training Accuracy\n",
    "y_pred_train_svm1 = svm_model1.predict(x_train_flat)\n",
    "training_accuracy = accuracy_score(y_train, y_pred_train_svm1)\n",
    "print(f'SVM Training Accuracy: {training_accuracy}')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c8c1b26-70d9-48df-b276-71b83b221ff5",
   "metadata": {},
   "source": [
    "Both SVM models, with and without validation, perform well, showing similar training and test accuracies. The model with validation achieves a test accuracy of 97.77% and training accuracy of 98.96%, while the model without validation slightly outperforms with a test accuracy of 97.92% and training accuracy of 98.99%. The close match between training and test accuracies in both models suggests no significant overfitting. Although the performance difference is minimal, using validation ensures better generalization, making it a more reliable approach overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42639a58-82c9-48a7-b746-f0b3008dde29",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4c60f-8eec-4233-a71a-5f9add7aea77",
   "metadata": {},
   "source": [
    "### KNN with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22a23d5a-4ef5-41ba-aa27-759d4112a8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Validation Accuracy: 0.9715\n",
      "KNN Test Accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "# Create and train the SVM model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# Validate on the validation set\n",
    "y_pred_val_knn = knn_model.predict(x_val_resampled)\n",
    "print(f'KNN Validation Accuracy: {accuracy_score(y_val_resampled, y_pred_val_knn)}')\n",
    "\n",
    "# Test on the test set\n",
    "y_pred_test_knn = knn_model.predict(x_test_flat)\n",
    "print(f'KNN Test Accuracy: {accuracy_score(y_test, y_pred_test_knn)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2fa7da8-35c4-4697-b92e-3eded5af12e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training Accuracy: 0.9797083333333333\n"
     ]
    }
   ],
   "source": [
    "# Calculate Training Accuracy\n",
    "y_pred_train_knn = knn_model.predict(x_train_resampled)\n",
    "training_accuracy_knn = accuracy_score(y_train_resampled, y_pred_train_knn)\n",
    "print(f'KNN Training Accuracy: {training_accuracy_knn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b754bc-cd62-4e65-b8ab-390839553b90",
   "metadata": {},
   "source": [
    "### KNN without validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dae407e7-017e-4140-b42e-677b092d2fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Test Accuracy: 0.9688\n",
      "KNN Training Accuracy: 0.9817083333333333\n"
     ]
    }
   ],
   "source": [
    "knn_model1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model1.fit(x_train_flat, y_train)\n",
    "\n",
    "# Test on the test set\n",
    "y_pred_test_knn1 = knn_model1.predict(x_test_flat)\n",
    "print(f'KNN Test Accuracy: {accuracy_score(y_test, y_pred_test_knn1)}')\n",
    "\n",
    "# Calculate Training Accuracy\n",
    "y_pred_train_knn1 = knn_model1.predict(x_train_resampled)\n",
    "training_accuracy_knn1 = accuracy_score(y_train_resampled, y_pred_train_knn1)\n",
    "print(f'KNN Training Accuracy: {training_accuracy_knn1}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d02e1476-05d9-4d85-9566-278d3eebdc6e",
   "metadata": {},
   "source": [
    "Both KNN models, with and without validation, show strong performance with similar training and test accuracies. The model with validation achieves a test accuracy of 96.7% and training accuracy of 97.97%, while the model without validation slightly outperforms with a test accuracy of 96.88% and training accuracy of 98.17%. The close match between training and test accuracies in both models indicates no significant overfitting. While the performance difference is small, using validation helps ensure better generalization, making it a more reliable approach overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637fa36-6db7-4e87-a162-56e9d1749f23",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36c4eb06-df01-47e8-a135-1bef57a26989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Training Accuracy: 0.9534166666666667\n",
      "Gradient Boosting Validation Accuracy: 0.94075\n",
      "Gradient Boosting Test Accuracy: 0.939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create and train the optimized Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=75, max_depth=3, warm_start=True)\n",
    "gb_model.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# Calculate Training Accuracy\n",
    "y_pred_train_gb = gb_model.predict(x_train_resampled)\n",
    "training_accuracy_gb = accuracy_score(y_train_resampled, y_pred_train_gb)\n",
    "print(f'Gradient Boosting Training Accuracy: {training_accuracy_gb}')\n",
    "\n",
    "# Validate on the validation set\n",
    "y_pred_val_gb = gb_model.predict(x_val_resampled)\n",
    "validation_accuracy_gb = accuracy_score(y_val_resampled, y_pred_val_gb)\n",
    "print(f'Gradient Boosting Validation Accuracy: {validation_accuracy_gb}')\n",
    "\n",
    "# Test on the test set\n",
    "y_pred_test_gb = gb_model.predict(x_test_flat)\n",
    "test_accuracy_gb = accuracy_score(y_test, y_pred_test_gb)\n",
    "print(f'Gradient Boosting Test Accuracy: {test_accuracy_gb}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9554fb-d813-426d-abf7-4846a16b0655",
   "metadata": {},
   "source": [
    "## Random Foest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fefc123-c9f8-4662-bd9e-27160f31fd1c",
   "metadata": {},
   "source": [
    "### Random Forest with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db728bee-24de-4019-8e24-80c42e7d60a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Accuracy: 1.0\n",
      "Random Forest Validation Accuracy: 0.9684166666666667\n",
      "Random Forest Test Accuracy: 0.9677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# Calculate Training Accuracy\n",
    "y_pred_train_rf = rf_model.predict(x_train_resampled)\n",
    "training_accuracy_rf = accuracy_score(y_train_resampled, y_pred_train_rf)\n",
    "print(f'Random Forest Training Accuracy: {training_accuracy_rf}')\n",
    "\n",
    "# Validate on the validation set\n",
    "y_pred_val_rf = rf_model.predict(x_val_resampled)\n",
    "validation_accuracy_rf = accuracy_score(y_val_resampled, y_pred_val_rf)\n",
    "print(f'Random Forest Validation Accuracy: {validation_accuracy_rf}')\n",
    "\n",
    "# Test on the test set\n",
    "y_pred_test_rf = rf_model.predict(x_test_flat)\n",
    "test_accuracy_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "print(f'Random Forest Test Accuracy: {test_accuracy_rf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ae3aa-ee7d-47d4-81fe-efbe2ce16b08",
   "metadata": {},
   "source": [
    "### Random Forest without validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9e9960c-114f-44f2-bcea-009758347a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Accuracy: 1.0\n",
      "Random Forest Test Accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Random Forest model\n",
    "rf_model1 = RandomForestClassifier()\n",
    "rf_model1.fit(x_train_flat, y_train)\n",
    "\n",
    "# Calculate Training Accuracy\n",
    "y_pred_train_rf1 = rf_model1.predict(x_train_flat)\n",
    "training_accuracy_rf1 = accuracy_score(y_train, y_pred_train_rf1)\n",
    "print(f'Random Forest Training Accuracy: {training_accuracy_rf1}')\n",
    "\n",
    "# Test on the test set\n",
    "y_pred_test_rf1 = rf_model1.predict(x_test_flat)\n",
    "test_accuracy_rf1 = accuracy_score(y_test, y_pred_test_rf1)\n",
    "print(f'Random Forest Test Accuracy: {test_accuracy_rf1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a89a78-cd0b-492f-a439-976a27c92bcd",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab862a6-2240-4dee-8d43-f5e176f7eeda",
   "metadata": {},
   "source": [
    "### Decision Tree with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1da8cc90-2cf4-4b8e-9a39-64ec64c6aefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Training Accuracy: 1.0\n",
      "Decision Tree Validation Accuracy: 0.8690833333333333\n",
      "Decision Tree Test Accuracy: 0.8744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create and train the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# Calculate Training Accuracy\n",
    "y_pred_train_dt = dt_model.predict(x_train_resampled)\n",
    "training_accuracy_dt = accuracy_score(y_train_resampled, y_pred_train_dt)\n",
    "print(f'Decision Tree Training Accuracy: {training_accuracy_dt}')\n",
    "\n",
    "# Validate on the validation set\n",
    "y_pred_val_dt = dt_model.predict(x_val_resampled)\n",
    "validation_accuracy_dt = accuracy_score(y_val_resampled, y_pred_val_dt)\n",
    "print(f'Decision Tree Validation Accuracy: {validation_accuracy_dt}')\n",
    "\n",
    "# Test on the test set\n",
    "y_pred_test_dt = dt_model.predict(x_test_flat)\n",
    "test_accuracy_dt = accuracy_score(y_test, y_pred_test_dt)\n",
    "print(f'Decision Tree Test Accuracy: {test_accuracy_dt}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8c347-799e-4af3-b949-a240a744d7b7",
   "metadata": {},
   "source": [
    "### Decision Tree without validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e2f8263-a175-4bdb-a5d8-0ee761e8c2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Training Accuracy: 1.0\n",
      "Decision Tree Test Accuracy: 0.8773\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Decision Tree model\n",
    "dt_model1 = DecisionTreeClassifier()\n",
    "dt_model1.fit(x_train_flat, y_train)\n",
    "\n",
    "# Calculate Training Accuracy\n",
    "y_pred_train_dt1 = dt_model1.predict(x_train_flat)\n",
    "training_accuracy_dt1 = accuracy_score(y_train, y_pred_train_dt1)\n",
    "print(f'Decision Tree Training Accuracy: {training_accuracy_dt1}')\n",
    "\n",
    "# Test on the test set\n",
    "y_pred_test_dt1 = dt_model1.predict(x_test_flat)\n",
    "test_accuracy_dt1 = accuracy_score(y_test, y_pred_test_dt1)\n",
    "print(f'Decision Tree Test Accuracy: {test_accuracy_dt1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76388db0-6c32-4f41-8fb2-b24caca177ad",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03d722e7-96be-41d5-b11b-67e77795acc0",
   "metadata": {},
   "source": [
    "To evaluate the performance of various classification models, we implemented a range of algorithms, including CNN, SVM, KNN, Random Forest, Decision Tree, and Gradient Descent Classifier. Each model was trained and tested with and without validation to assess the benefits of validation in ensuring model generalization. Validation sets were used to tune hyperparameters, helping models avoid overfitting. For models such as Gradient Boosting Classifier, only validation was applied due to the time-intensive nature of compiling the model. We also tested an optimized CNN after noticing that the basic CNN didn’t achieve the desired accuracy. The optimized CNN incorporated additional layers and tuned hyperparameters for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e861cfc-6140-468e-89c5-9d4095370084",
   "metadata": {},
   "source": [
    "# Observation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec93a634-1e66-4fdb-ac2c-34fd7e32198b",
   "metadata": {},
   "source": [
    "The optimized CNN achieved the highest test accuracy of 98.9%, outperforming the basic CNN, which only reached 97.6%. Among the traditional ML models, the SVM without validation showed a marginal improvement in test accuracy (97.9%) over the version with validation (97.79%), although the latter demonstrated better model robustness. Similarly, KNN and Random Forest with validation resulted in slightly lower test accuracies compared to the non-validation versions, showing 96.7% and 96.77%, respectively, but ensured more consistent performance across datasets. The Decision Tree models, however, performed poorly overall, with validation showing a test accuracy of 87.44%, while the version without validation was only slightly better at 87.73%. The Gradient Descent Classifier reached 93.9% test accuracy but took considerable time to compile, prompting us to evaluate it only with validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228eac5d-5758-45f3-82b5-ffd214d2d6f2",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8e112ac-fc49-4948-8db8-71e357e7a336",
   "metadata": {},
   "source": [
    "Validation plays a key role in ensuring model generalization and robustness, even though it may slightly reduce test accuracy in some cases, as observed in models like SVM, KNN, and Random Forest. The optimized CNN emerged as the top-performing model, demonstrating the importance of tuning and improving model architecture when simple networks fail to achieve desired results. While non-validated models occasionally outperformed validated ones, validation remains a critical step for ensuring that the model will generalize well on unseen data. The Gradient Descent Classifier, while slower to compile, provides a reasonable accuracy trade-off, but the time overhead makes it less practical for large datasets or time-sensitive tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64f156c-9040-4fe4-80fd-b9ff3eebd47c",
   "metadata": {},
   "source": [
    "# Project Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a11df0ac-1fe4-45cc-9ce6-7419d6d07381",
   "metadata": {},
   "source": [
    "This project analyzed the performance of various classification models, including SVM, KNN, Random Forest, Decision Tree, Gradient Descent Classifier, and CNN. The optimized CNN achieved the highest accuracy at 98.9%, showing the value of tuning model architecture. Among machine learning models, SVM performed best with a test accuracy of 97.9% without validation, though validation improved model generalization. Due to high compilation time, the Gradient Descent Classifier was tested only with validation, achieving 93.9% accuracy. The project highlighted the importance of both architectural optimization in deep learning and validation in machine learning for reliable results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
